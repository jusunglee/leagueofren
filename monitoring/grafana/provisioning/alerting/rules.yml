apiVersion: 1

groups:
  - orgId: 1
    name: Service Health
    folder: Alerts
    interval: 1m
    rules:
      - uid: service-down
        title: Service Down
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              expr: up == 0
              instant: true
              refId: A
          - refId: B
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: reduce
              expression: A
              reducer: last
              refId: B
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    type: gt
                    params:
                      - 0
              refId: C
        noDataState: OK
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "{{ $labels.job }} is down"

      - uid: high-error-rate
        title: High Error Rate
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              expr: >
                sum(rate(lor_http_requests_total{status=~"5.."}[5m]))
                /
                sum(rate(lor_http_requests_total[5m]))
                * 100
              instant: true
              refId: A
          - refId: B
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: reduce
              expression: A
              reducer: last
              refId: B
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    type: gt
                    params:
                      - 5
              refId: C
        noDataState: OK
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "HTTP 5xx error rate is above 5%"

  - orgId: 1
    name: Translations
    folder: Alerts
    interval: 1m
    rules:
      - uid: failed-translations
        title: Failed Translations
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              expr: rate(lor_translation_submissions_total{result="failed"}[5m])
              instant: true
              refId: A
          - refId: B
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: reduce
              expression: A
              reducer: last
              refId: B
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    type: gt
                    params:
                      - 0
              refId: C
        noDataState: OK
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Translation submissions are failing"

      - uid: llm-translation-slow
        title: LLM Translation Slow
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              expr: histogram_quantile(0.95, sum(rate(lor_llm_translation_duration_seconds_bucket[5m])) by (le))
              instant: true
              refId: A
          - refId: B
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: reduce
              expression: A
              reducer: last
              refId: B
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    type: gt
                    params:
                      - 15
              refId: C
        noDataState: OK
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "LLM translation p95 latency is above 15s"

  - orgId: 1
    name: External APIs
    folder: Alerts
    interval: 1m
    rules:
      - uid: riot-api-errors
        title: Riot API Errors
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              expr: >
                sum(rate(lor_riot_api_calls_total{result="error"}[5m]))
                /
                sum(rate(lor_riot_api_calls_total[5m]))
                * 100
              instant: true
              refId: A
          - refId: B
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: reduce
              expression: A
              reducer: last
              refId: B
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    type: gt
                    params:
                      - 10
              refId: C
        noDataState: OK
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Riot API error rate is above 10%"

      - uid: worker-stalled
        title: Worker Stalled
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 7200
              to: 0
            datasourceUid: prometheus
            model:
              expr: sum(increase(lor_worker_refresh_duration_seconds_count[2h]))
              instant: true
              refId: A
          - refId: B
            relativeTimeRange:
              from: 7200
              to: 0
            datasourceUid: __expr__
            model:
              type: reduce
              expression: A
              reducer: last
              refId: B
          - refId: C
            relativeTimeRange:
              from: 7200
              to: 0
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    type: lt
                    params:
                      - 1
              refId: C
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Worker has not completed a refresh cycle in 2 hours"

  - orgId: 1
    name: Discord Bot
    folder: Alerts
    interval: 1m
    rules:
      - uid: bot-command-failures
        title: Bot Command Failures
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              expr: sum(rate(lor_bot_commands_total{result="error"}[5m]))
              instant: true
              refId: A
          - refId: B
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: reduce
              expression: A
              reducer: last
              refId: B
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    type: gt
                    params:
                      - 0
              refId: C
        noDataState: OK
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Discord bot commands are failing"

  - orgId: 1
    name: Infrastructure
    folder: Alerts
    interval: 1m
    rules:
      - uid: db-pool-near-exhaustion
        title: DB Pool Near Exhaustion
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              expr: lor_db_pool_acquired_conns / lor_db_pool_max_conns * 100
              instant: true
              refId: A
          - refId: B
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: reduce
              expression: A
              reducer: last
              refId: B
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    type: gt
                    params:
                      - 80
              refId: C
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Database connection pool is above 80% capacity"

      - uid: high-rate-limiting
        title: High Rate Limiting
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              expr: rate(lor_rate_limit_hits_total[5m]) * 60
              instant: true
              refId: A
          - refId: B
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: reduce
              expression: A
              reducer: last
              refId: B
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    type: gt
                    params:
                      - 30
              refId: C
        for: 10m
        labels:
          severity: info
        annotations:
          summary: "Rate limit hits are above 30/min"

      - uid: vote-spam
        title: Vote Spam
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: prometheus
            model:
              expr: sum(rate(lor_votes_total[5m]))
              instant: true
              refId: A
          - refId: B
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: reduce
              expression: A
              reducer: last
              refId: B
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    type: gt
                    params:
                      - 1
              refId: C
        for: 5m
        labels:
          severity: info
        annotations:
          summary: "Vote rate exceeds 1/sec â€” possible spam"
